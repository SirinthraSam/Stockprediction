{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will show you how to write a python program that predicts the price of stocks using a machine learning technique called Long Short-Term Memory (LSTM). This program is really simple and I doubt any major profit will be made from this program, but itâ€™s slightly better than guessing! Remember the stock price can be affected by many different things.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be solve the following question:\n",
    "1. What was the change in price of the stock over time?\n",
    "2. What was the daily return of the stock on average?\n",
    "3. What was the moving average of the various stocks?\n",
    "4. What was the correlation between different stocks'?\n",
    "5. How much value do we put at risk by investing in a particular stock?\n",
    "6. How can we attempt to predict future stock behavior? (Predicting the closing price stock price of APPLE inc using LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inroduction\n",
    "2. Importing libraries\n",
    "3. Reading datasets\n",
    "4. Building Models\n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-91951ba6bdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here we are importing important libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mweb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "# here we are importing important libraries\n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What was the change in price of the stock overtime?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are making tech list which we will use for this analysis\n",
    "Tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
    "# now we are setting end and start time for grabing data\n",
    "end = datetime.now()\n",
    "start = datetime(end.year-1,end.month,end.day)\n",
    "# now we are using for loop for grabing yahoo data and setting it in form of dataframe\n",
    "#  Using globals() is a sloppy way of setting the DataFrame names, but its simple\n",
    "for stock in Tech_list:\n",
    "    globals()[stock] = web.DataReader(stock,\"yahoo\",start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are making list of our company\n",
    "Company_list = [AAPL,GOOG,MSFT,AMZN]\n",
    "company_name = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
    "for company, comp_name in zip(Company_list,company_name):\n",
    "    company[\"company_name\"] = comp_name\n",
    "    \n",
    "df = pd.concat(Company_list,axis=0)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are summarize stats \n",
    "AAPL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are printing information of our dataset\n",
    "AAPL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are visualising of closing price\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplots_adjust(top=1.25, bottom=1.2)\n",
    "\n",
    "for i, company in enumerate(Company_list, 1):\n",
    "    plt.subplot(2, 2,i)\n",
    "    company['Adj Close'].plot()\n",
    "    plt.ylabel('Adj Close')\n",
    "    plt.xlabel(None)\n",
    "    plt.title(f\"{Tech_list[i - 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are visualising total volume of stock being trade each day\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplots_adjust(top=1.25, bottom=1.2)\n",
    "\n",
    "for i, company in enumerate(Company_list, 1):\n",
    "    plt.subplot(2, 2,i)\n",
    "    company['Volume'].plot()\n",
    "    plt.ylabel('Volume')\n",
    "    plt.xlabel(None)\n",
    "    plt.title(f\"{Tech_list[i - 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen the visualizations for the closing price and the volume traded each day, let's go ahead and caculate the moving average for the stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What was the moving average of the various stocks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three important moving averages that can be applied to your charts that will help you trade better. They are the 10 moving average, the 20 moving average and the 50 moving average.\n",
    "The 20 moving average (10MA) is the short-term outlook.\n",
    "The 50 moving average (20MA) is the medium term outlook.\n",
    "The 200 moving average (50MA) is the trend bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_day = [10, 20, 50]\n",
    "\n",
    "for ma in ma_day:\n",
    "    for company in Company_list:\n",
    "        column_name = f\"MA for {ma} days\"\n",
    "        company[column_name] = company['Adj Close'].rolling(ma).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are printing columns of google company\n",
    "print(GOOG.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are visualising the additional moving averages\n",
    "df.groupby(\"company_name\").hist(figsize=(12, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are visualising three important moving averages of all the company\n",
    "fig, axes = plt.subplots(nrows=2,ncols=2)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "AAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])\n",
    "axes[0,0].set_title('APPLE')\n",
    "\n",
    "GOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])\n",
    "axes[0,1].set_title('GOOGLE')\n",
    "\n",
    "MSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])\n",
    "axes[1,0].set_title('MICROSOFT')\n",
    "\n",
    "AMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])\n",
    "axes[1,1].set_title('AMAZON')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What was the daily return of the stock on average?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done some baseline analysis, let's go ahead and dive a little deeper. We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value. Let's go ahead and use pandas to retrieve teh daily returns for the Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use pct_change to find the percent change for each day\n",
    "for company in Company_list:\n",
    "    company['Daily Return'] = company['Adj Close'].pct_change()\n",
    "\n",
    "# Then we'll plot the daily return percentage\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "AAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\n",
    "axes[0,0].set_title('APPLE')\n",
    "\n",
    "GOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')\n",
    "axes[0,1].set_title('GOOGLE')\n",
    "\n",
    "MSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')\n",
    "axes[1,0].set_title('MICROSOFT')\n",
    "\n",
    "AMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')\n",
    "axes[1,1].set_title('AMAZON')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of dropna() here, otherwise the NaN values can't be read by seaborn\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, company in enumerate(Company_list, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.distplot(company['Daily Return'].dropna(), bins=100, color='blue')\n",
    "    plt.ylabel('Daily Return')\n",
    "    plt.title(f'{company_name[i - 1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What was the correlation between different stocks closing prices?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Grabing all the closing prices for the tech stock list into one DataFrame\n",
    "closing_df = web.DataReader(Tech_list, 'yahoo', start, end)['Adj Close']\n",
    "# here we are printing first five line\n",
    "closing_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Making a new tech returns DataFrame\n",
    "tech_rets = closing_df.pct_change()\n",
    "tech_rets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are comparing Google to itself should show a perfectly linear relationship\n",
    "sns.jointplot('GOOG', 'GOOG', tech_rets, kind='scatter', color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here We'll use joinplot to compare the daily returns of Google and Microsoft\n",
    "sns.jointplot('GOOG', 'MSFT', tech_rets, kind='scatter', color = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can see that if two stocks are perfectly (and positivley) correlated with each other a linear relationship bewteen its daily return values should occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are simply calling pairplot on our DataFrame for an automatic visual analysis \n",
    "# of all the comparisons\n",
    "sns.pairplot(tech_rets, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
    "return_fig = sns.PairGrid(tech_rets.dropna())\n",
    "\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "return_fig.map_upper(plt.scatter, color='green')\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) \n",
    "# or the color map (BluePurple)\n",
    "return_fig.map_lower(sns.kdeplot, cmap='cool_d')\n",
    "\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
    "return_fig.map_diag(plt.hist, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
    "returns_fig = sns.PairGrid(closing_df)\n",
    "\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "returns_fig.map_upper(plt.scatter,color='green')\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
    "returns_fig.map_lower(sns.kdeplot,cmap='cool_d')\n",
    "\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
    "returns_fig.map_diag(plt.hist,bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we could also do a correlation plot, to get actual numerical values for the correlation between the stocks' daily return values. By comparing the closing prices, we see an interesting relationship between Microsoft and Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using seabron for a quick correlation plot for the daily returns\n",
    "sns.heatmap(tech_rets.corr(), annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(closing_df.corr(), annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Just like we suspected in our PairPlot we see here numerically and visually that Microsoft and Amazon had the strongest correlation of daily stock return. It's also interesting to see that all the technology comapnies are positively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. How much value do we put at risk by investing in a particular stock?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here e are defining a new DataFrame as a cleaned version of the oriignal tech_rets DataFrame\n",
    "rets = tech_rets.dropna()\n",
    "\n",
    "area = np.pi*20\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(rets.mean(), rets.std(), s=area)\n",
    "plt.xlabel('Expected return')\n",
    "plt.ylabel('Risk')\n",
    "\n",
    "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', \n",
    "                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Predicting the closing price stock price of APPLE inc:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Getting the stock quote\n",
    "df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end=datetime.now())\n",
    "# printing the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are printing shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2183 rows and 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Visualising the closing price history\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Close Price History')\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new data frame with only the closing price and convert it to an array.\n",
    "Then create a variable to store the length of the training data set. I want the training data set to contain about 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new dataframe with only the 'Close' column\n",
    "data = df.filter(['Close'])\n",
    "#Converting the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#Get /Compute the number of rows to train the model on\n",
    "training_data_len = math.ceil( len(dataset) *.8)\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scale the data set to be values between 0 and 1 inclusive, I do this because it is generally good practice to scale your data before giving it to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Scaling the all of the data to be values between 0 and 1 \n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the scaled training data set\n",
    "train_data = scaled_data[0:training_data_len  , : ]\n",
    "#Spliting the data into x_train and y_train data sets\n",
    "x_train=[]\n",
    "y_train = []\n",
    "for i in range(60,len(train_data)):\n",
    "    x_train.append(train_data[i-60:i,0])\n",
    "    y_train.append(train_data[i,0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b911c159be6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Here we are Converting x_train and y_train to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Here we are Converting x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are reshaping the data into the shape accepted by the LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are Building the LSTM network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are training the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are testing data set\n",
    "test_data = scaled_data[training_data_len - 60: , : ]\n",
    "#Creating the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test =  dataset[training_data_len : , : ] #Get all of the rows from index 1603 to the rest and all of the columns (in this case it's only column 'Close'), so 2003 - 1603 = 400 rows of data\n",
    "for i in range(60,len(test_data)):\n",
    "    x_test.append(test_data[i-60:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are converting x_test to a numpy array  \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are reshaping the data into the shape accepted by the LSTM  \n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are getting the models predicted price values\n",
    "predictions = model.predict(x_test) \n",
    "predictions = scaler.inverse_transform(predictions)#Undo scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are calculaing the value of RMSE \n",
    "rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot/Create the data for the graph\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "#Visualize the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for reading. I hope you like my analysing and visualization and found it to be helpful. If you have any questions or suggestions, feel free to write them down in the comment section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
